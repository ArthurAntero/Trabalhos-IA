{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T3 de NoIA\n",
    "\n",
    "Neste trabalho, vamos aprender ...\n",
    "\n",
    "Para que funcione corretamente, vá ao site https://www.statmt.org/europarl/ , encontre o link “parallel corpus Portuguese-English” o baixe e crie uma pasta \"texts\" e coloque os dois arquivos que serão baixados nessa pasta \"texts \"na raiz do projeto.\n",
    "\n",
    "## Alunos\n",
    "- **Arthur de Sá Antero - 212006577**\n",
    "- **Arthur Mota Furtado - 200014935**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inglês: [['resumption', 'of', 'the', 'session'], ['i', 'declare', 'resumed', 'the', 'session', 'of', 'the', 'european', 'parliament', 'adjourned', 'on', 'friday', '17', 'december', '1999', 'and', 'i', 'would', 'like', 'once', 'again', 'to', 'wish', 'you', 'a', 'happy', 'new', 'year', 'in', 'the', 'hope', 'that', 'you', 'enjoyed', 'a', 'pleasant', 'festive', 'period'], ['although', 'as', 'you', 'will', 'have', 'seen', 'the', 'dreaded', 'millennium', 'bug', 'failed', 'to', 'materialise', 'still', 'the', 'people', 'in', 'a', 'number', 'of', 'countries', 'suffered', 'a', 'series', 'of', 'natural', 'disasters', 'that', 'truly', 'were', 'dreadful'], ['you', 'have', 'requested', 'a', 'debate', 'on', 'this', 'subject', 'in', 'the', 'course', 'of', 'the', 'next', 'few', 'days', 'during', 'this', 'partsession'], ['in', 'the', 'meantime', 'i', 'should', 'like', 'to', 'observe', 'a', 'minute', 's', 'silence', 'as', 'a', 'number', 'of', 'members', 'have', 'requested', 'on', 'behalf', 'of', 'all', 'the', 'victims', 'concerned', 'particularly', 'those', 'of', 'the', 'terrible', 'storms', 'in', 'the', 'various', 'countries', 'of', 'the', 'european', 'union']]\n",
      "Português: [['reinício', 'da', 'sessão'], ['declaro', 'reaberta', 'a', 'sessão', 'do', 'parlamento', 'europeu', 'que', 'tinha', 'sido', 'interrompida', 'na', 'sextafeira', '17', 'de', 'dezembro', 'último', 'e', 'renovo', 'todos', 'os', 'meus', 'votos', 'esperando', 'que', 'tenham', 'tido', 'boas', 'férias'], ['como', 'puderam', 'constatar', 'o', 'grande', 'bug', 'do', 'ano', '2000', 'não', 'aconteceu', 'em', 'contrapartida', 'os', 'cidadãos', 'de', 'alguns', 'dos', 'nossos', 'países', 'foram', 'vítimas', 'de', 'catástrofes', 'naturais', 'verdadeiramente', 'terríveis'], ['os', 'senhores', 'manifestaram', 'o', 'desejo', 'de', 'se', 'proceder', 'a', 'um', 'debate', 'sobre', 'o', 'assunto', 'nos', 'próximos', 'dias', 'durante', 'este', 'período', 'de', 'sessões'], ['entretanto', 'gostaria', 'como', 'também', 'me', 'foi', 'pedido', 'por', 'um', 'certo', 'número', 'de', 'colegas', 'que', 'observássemos', 'um', 'minuto', 'de', 'silêncio', 'por', 'todas', 'as', 'vítimas', 'nomeadamente', 'das', 'tempestades', 'nos', 'diferentes', 'países', 'da', 'união', 'europeia', 'que', 'foram', 'afectados']]\n",
      "[AlignedSent(['reinício', 'da', 'sessão'], ['resumption', 'of', 'the', 'session'], Alignment([])), AlignedSent(['declaro', 'reaberta', 'a', 'sessão', 'do', 'parlamento', 'europeu', 'que', 'tinha', 'sido', 'interrompida', 'na', 'sextafeira', '17', 'de', 'dezembro', 'último', 'e', 'renovo', 'todos', 'os', 'meus', 'votos', 'esperando', 'que', 'tenham', 'tido', 'boas', 'férias'], ['i', 'declare', 'resumed', 'the', 'session', 'of', 'the', 'european', 'parliament', 'adjourned', 'on', 'friday', '17', 'december', '1999', 'and', 'i', 'would', 'like', 'once', 'again', 'to', 'wish', 'you', 'a', 'happy', 'new', 'year', 'in', 'the', 'hope', 'that', 'you', 'enjoyed', 'a', 'pleasant', 'festive', 'period'], Alignment([])), AlignedSent(['como', 'puderam', 'constatar', 'o', 'grande', 'bug', 'do', 'ano', '2000', 'não', 'aconteceu', 'em', 'contrapartida', 'os', 'cidadãos', 'de', 'alguns', 'dos', 'nossos', 'países', 'foram', 'vítimas', 'de', 'catástrofes', 'naturais', 'verdadeiramente', 'terríveis'], ['although', 'as', 'you', 'will', 'have', 'seen', 'the', 'dreaded', 'millennium', 'bug', 'failed', 'to', 'materialise', 'still', 'the', 'people', 'in', 'a', 'number', 'of', 'countries', 'suffered', 'a', 'series', 'of', 'natural', 'disasters', 'that', 'truly', 'were', 'dreadful'], Alignment([])), AlignedSent(['os', 'senhores', 'manifestaram', 'o', 'desejo', 'de', 'se', 'proceder', 'a', 'um', 'debate', 'sobre', 'o', 'assunto', 'nos', 'próximos', 'dias', 'durante', 'este', 'período', 'de', 'sessões'], ['you', 'have', 'requested', 'a', 'debate', 'on', 'this', 'subject', 'in', 'the', 'course', 'of', 'the', 'next', 'few', 'days', 'during', 'this', 'partsession'], Alignment([])), AlignedSent(['entretanto', 'gostaria', 'como', 'também', 'me', 'foi', 'pedido', 'por', 'um', 'certo', 'número', 'de', 'colegas', 'que', 'observássemos', 'um', 'minuto', 'de', 'silêncio', 'por', 'todas', 'as', 'vítimas', 'nomeadamente', 'das', 'tempestades', 'nos', 'diferentes', 'países', 'da', 'união', 'europeia', 'que', 'foram', 'afectados'], ['in', 'the', 'meantime', 'i', 'should', 'like', 'to', 'observe', 'a', 'minute', 's', 'silence', 'as', 'a', 'number', 'of', 'members', 'have', 'requested', 'on', 'behalf', 'of', 'all', 'the', 'victims', 'concerned', 'particularly', 'those', 'of', 'the', 'terrible', 'storms', 'in', 'the', 'various', 'countries', 'of', 'the', 'european', 'union'], Alignment([]))]\n",
      "8.636168555094496e-78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bomdia/miniconda3/envs/gpu/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.translate import IBMModel1, AlignedSent\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "file_en = \"texts/europarl-v7.pt-en.en\"\n",
    "file_pt = \"texts/europarl-v7.pt-en.pt\"\n",
    "\n",
    "with open(file_en, \"r\", encoding=\"utf-8\") as f_en, open(file_pt, \"r\", encoding=\"utf-8\") as f_pt:\n",
    "    source_sentences = f_en.readlines()  # Inglês\n",
    "    target_sentences = f_pt.readlines()  # Português\n",
    "\n",
    "source_sentences = [clean_text(line.strip()).split() for line in source_sentences[:100000]]\n",
    "target_sentences = [clean_text(line.strip()).split() for line in target_sentences[:100000]]\n",
    "\n",
    "print(\"Inglês:\", source_sentences[:5])\n",
    "print(\"Português:\", target_sentences[:5])\n",
    "\n",
    "bitext = [AlignedSent(target, source) for source, target in zip(source_sentences, target_sentences)]\n",
    "print(bitext[:5])\n",
    "\n",
    "ibm_model = IBMModel1(bitext, 5)\n",
    "\n",
    "reference = [['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'is', 'a', 'trial']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(sentences):\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r\"[^a-zA-Z0-9]+\", \" \", sentence)\n",
    "        cleaned_sentences.append(sentence.strip())\n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_input(ibm_model, source_text):\n",
    "    cleaned_text = clean_sentences(source_text.split())\n",
    "    source_words = cleaned_text\n",
    "    translated_words = []\n",
    "    for source_word in source_words:\n",
    "        max_prob = 0.0\n",
    "        translated_word = None\n",
    "        for target_word in ibm_model.translation_table[source_word]:\n",
    "            prob = ibm_model.translation_table[source_word][target_word]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                translated_word = target_word\n",
    "        if translated_word is not None:\n",
    "            translated_words.append(translated_word)\n",
    "    translated_text = ' '.join(translated_words)\n",
    "\n",
    "    return translated_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'day']\n"
     ]
    }
   ],
   "source": [
    "print(translate_input(ibm_model, \"Bom dia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['want', 'colourful', 'genuine', 'culture', 'resumption', 'stridency', 'europe']\n",
      "['we', 'want', 'a', 'true', 'culture', 'of', 'competition', 'in', 'europe']\n",
      "queremos uma verdadeira cultura da concorrência na europa\n",
      "1.1077199809555581e-231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bomdia/miniconda3/envs/gpu/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bomdia/miniconda3/envs/gpu/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bomdia/miniconda3/envs/gpu/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "sentence = \" \".join(target_sentences[1000])\n",
    "correct_sentence = source_sentences[1000]\n",
    "translation = translate_input(ibm_model, sentence)\n",
    "print(translation)\n",
    "print(correct_sentence)\n",
    "print(sentence)\n",
    "score = sentence_bleu([correct_sentence], translation)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
